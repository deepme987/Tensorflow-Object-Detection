{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Object Detection: Face Mask Detection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deepme987/Tensorflow-Object-Detection/blob/master/Object_Detection_Face_Mask_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4k8dCr83iV3"
      },
      "source": [
        "# **Object Detection Tutorial**\n",
        "\n",
        "---\n",
        "\n",
        "This notebook is associated with the blog \"Object Detection using Tensorflow 2: Building a Face Mask Detector on Google Colab\". It contains the code used in the tutorial. You're free to re-use, modify or share this notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UL-PoKo_4cHv"
      },
      "source": [
        "# Installing required packages for Tensorflow Object Detection\n",
        "\n",
        "We install the pre-required packages for Object Detection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJyanOLlcxVc",
        "outputId": "d91243ff-31b8-410c-9c60-6dc727de6660",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Ensure to use the GPU runtime\n",
        "\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Nov  9 17:07:43 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.32.00    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   61C    P8    11W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3K_1SvEt6Od-"
      },
      "source": [
        "\n",
        "## 1. Clone Tensorflow-Object-Detection repository\n",
        "\n",
        "Repository link: https://github.com/deepme987/Tensorflow-Object-Detection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPlT2LEiHBo4",
        "outputId": "5b2a73ff-b9ce-4d6b-8bd7-71abcce3b085",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Clone our github repository to access utility files for data preparation\n",
        "# Respository: https://github.com/deepme987/Tensorflow-Object-Detection\n",
        "\n",
        "!git clone https://github.com/deepme987/Tensorflow-Object-Detection\n",
        "%cd Tensorflow-Object-Detection"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Tensorflow2-Object-Detection'...\n",
            "remote: Enumerating objects: 29, done.\u001b[K\n",
            "remote: Counting objects: 100% (29/29), done.\u001b[K\n",
            "remote: Compressing objects: 100% (27/27), done.\u001b[K\n",
            "remote: Total 29 (delta 11), reused 3 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (29/29), done.\n",
            "/content/Tensorflow2-Object-Detection\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CrBiYGx5eeK"
      },
      "source": [
        "## 2. Cloning the Tensorflow library and building the package.\n",
        "\n",
        "Installation Guide followed from [Tensorflow](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2.mdhttps://)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xk2IkqHDRTxi"
      },
      "source": [
        "# Upgrade pip to latest version\n",
        "!pip install pip --upgrade\n",
        "\n",
        "# Download Object Detection API and build necessary files\n",
        "\n",
        "%cd /content\n",
        "!git clone --quiet https://github.com/tensorflow/models.git\n",
        "\n",
        "%cd /content/models/research/\n",
        "# Compile protos.\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "# Install TensorFlow Object Detection API.\n",
        "%cp object_detection/packages/tf2/setup.py .\n",
        "!python -m pip install --use-feature=2020-resolver .\n",
        "\n",
        "!python object_detection/builders/model_builder_tf2_test.py\n",
        "%cd /content/Tensorflow-Object-Detection"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1JYQJQf46V2"
      },
      "source": [
        "# Downloading the data\n",
        "\n",
        "You can download the data on your local machine and upload it on colab. For larger datasets, provided by Kaggle, you can download them directly to colab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4QvfwxQ6UmP"
      },
      "source": [
        "## 1. To upload from local machine:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q86qxRL2UW-S"
      },
      "source": [
        "''' Download Dataset on your local machine and upload to /content/Tensorflow-Object-Detection'''\n",
        "# Upload the dataset to colab\n",
        "\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "\n",
        "# Unzipping the content\n",
        "!unzip archive.zip\n",
        "!rm archive.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGoWOkGi6Z1u"
      },
      "source": [
        "## 2. To download directly from Kaggle\n",
        "\n",
        "You need to first download your Kaggle API key. You can find it by logging in to Kaggle under \"My Account\" tab.\n",
        "\n",
        "It will download a file named kaggle.json which can be uploaded here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEuEh8xvY7Ed"
      },
      "source": [
        "''' Download Dataset through Kaggle API'''\n",
        "\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "\n",
        "# upload kaggle.json: Your account's API Key downloaded from kaggle\n",
        "\n",
        "# Install kaggle and change permissions for the uploaded json file \n",
        "\n",
        "!pip install -q kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "\n",
        "!rm kaggle.json\n",
        "\n",
        "!kaggle datasets download -d andrewmvd/face-mask-detection \n",
        "!unzip face-mask-detection.zip\n",
        "!rm face-mask-detection.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IjpcCdN6yEc"
      },
      "source": [
        "# Data Preparations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imzGMmll60r3"
      },
      "source": [
        "## 1. Looking into the data\n",
        "\n",
        "We open few random images from the downloaded dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wzy92d5QbbQR"
      },
      "source": [
        "# Check few images in the dataset\n",
        "\n",
        "import random\n",
        "import cv2\n",
        "import glob\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Change the extension accordingly if your dataset is not png\n",
        "TEST_IMAGE_PATHS = glob.glob('images/*.png')\n",
        "\n",
        "# Change the value of k to the number of images to display\n",
        "try:\n",
        "    images = random.sample(TEST_IMAGE_PATHS, k=3)\n",
        "except:\n",
        "    # Exception incase the value of k is higher than available samples\n",
        "    images = TEST_IMAGE_PATHS\n",
        "\n",
        "\n",
        "for image_path in images:\n",
        "    print(image_path)\n",
        "    img = cv2.imread(image_path)\n",
        "    cv2_imshow(img)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amSg0_GJ7AfP"
      },
      "source": [
        "## 2. Converting the XML data into CSV file\n",
        "\n",
        "TFRecords are generated using csv files. However, in case your data is annotated in XML format, you can use this script from the Tensorflow-Object-Detection repository we cloned earlier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXjcA6TsdEJC",
        "outputId": "f10b5109-4a49-4616-f4a3-31b5027e12bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# The dataset contains all annotations in xml format. \n",
        "# However, we need csv files for Object Detection\n",
        "# Change <PATH TO ANNOTATIONS> to point annotation directory and\n",
        "# <OUTPUT FILE NAME> as required filename.csv for custom dataset\n",
        "\n",
        "# !python xml_to_csv.py --xml_path=<PATH TO ANNOTATIONS> --csv_output=<OUTPUT FILE NAME>\n",
        "\n",
        "!python xml_to_csv.py --xml_path=annotations/ --csv_output=annotations.csv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading xml from folder annotations/\n",
            "Successfully converted xml to csv.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWLShh927P6u"
      },
      "source": [
        "## 3. Reading the annotations and splitting into train and test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBYE347eJIvn"
      },
      "source": [
        "# Read all annotations from the generated csv\n",
        "\n",
        "import pandas as pd\n",
        "data = pd.read_csv(\"annotations.csv\")\n",
        "data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8V1RRQBN6kv"
      },
      "source": [
        "# Split data into train-test\n",
        "# Avoid using sklearn's train_test_split to split the data as it may use \n",
        "# same image in train as well as test for different annotation \n",
        "\n",
        "from sklearn.model_selection import GroupShuffleSplit\n",
        "\n",
        "# You can change the test_size below (ideally between 0.2-0.4)\n",
        "train_inds, test_inds = next(GroupShuffleSplit(test_size=0.30, random_state = 7).split(data, groups=data['filename']))\n",
        "\n",
        "train = data.iloc[train_inds]\n",
        "test = data.iloc[test_inds]\n",
        "\n",
        "\n",
        "# Export the csv files, we'll use these for generating tfrecords\n",
        "train.to_csv(\"train_labels.csv\")\n",
        "test.to_csv(\"test_labels.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jUn2Xb57Yui"
      },
      "source": [
        "## 4. Generating labelmap.pbtxt\n",
        "\n",
        "A labelmap.pbtxt file consists of class ID mapped to their class names. Since Tensorflow models deal with only numeric values, we need to convert the string class names into numbers, starting with 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFuzFexJPJRL"
      },
      "source": [
        "# Generate labelmap.pbtxt based on training labels.\n",
        "\n",
        "ob = \"{\"\n",
        "cb = \"}\"\n",
        "nl = \"\\n\"\n",
        "\n",
        "string = \"\"\n",
        "for i, class_ in enumerate(set(train[\"class\"])):\n",
        "    string += f\"\"\"\n",
        "item {ob} \n",
        "  id: {i+1}\n",
        "  name: '{class_}'\n",
        "{cb}\"\"\"\n",
        "\n",
        "with open(\"labelmap.pbtxt\", 'w') as file:\n",
        "    file.write(string)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lY3AtZ49eEh",
        "outputId": "35f97eb4-a52e-416f-f092-ce2a88b4e3dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Check the labelmap file\n",
        "\n",
        "!cat labelmap.pbtxt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "item { \n",
            "  id: 1\n",
            "  name: 'with_mask'\n",
            "}\n",
            "item { \n",
            "  id: 2\n",
            "  name: 'mask_weared_incorrect'\n",
            "}\n",
            "item { \n",
            "  id: 3\n",
            "  name: 'without_mask'\n",
            "}"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dtg-t3tR7ngM"
      },
      "source": [
        "## 5. Create TFRecords\n",
        "\n",
        "We use the previously generated train and test data records with images and labelmap to build the TFRecords that will be used for training the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yudw6U-CQn9x",
        "outputId": "84dc70dd-ba64-402c-d115-9cfbfed9863d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Tensorflow uses tfrecord files for training\n",
        "# To Generate tfrecord files based on input data (images and csv files).\n",
        "# For huge datasets, this step may take long time \n",
        "# May take hours for dataset above 5GB\n",
        "\n",
        "# Change the image path accordingly for your custom dataset\n",
        "!python generate_tfrecord.py --csv_input train_labels.csv --output_path train.record --img_path=\"images/\" --label_map labelmap.pbtxt\n",
        "!python generate_tfrecord.py --csv_input test_labels.csv --output_path test.record --img_path=\"images/\" --label_map labelmap.pbtxt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-11-09 17:14:53.233937: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "Successfully created the TFRecords: /content/Tensorflow2-Object-Detection/train.record\n",
            "2020-11-09 17:14:56.969550: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "Successfully created the TFRecords: /content/Tensorflow2-Object-Detection/test.record\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZ1IXPAL71p1"
      },
      "source": [
        "# Training the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEe_XrOq77Aa"
      },
      "source": [
        "## 1. Model Configurations\n",
        "\n",
        "\n",
        "\n",
        "1.   Number of steps(num_steps): This specifies how many objects should the model train for.\n",
        "2.   Model Name(selected_model): The name of the model available to download.\n",
        "3.   Pipeline Name: The configuration file for the model available. \n",
        "4.   Batch Size: A batch size refers to how many instances of data will be considered at a time during training. \n",
        "\n",
        "You can find a detailed explanation of the model configurations in the tutorial blog."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjrowxV8V-5v"
      },
      "source": [
        "# Model vars\n",
        "\n",
        "# Number of training steps.\n",
        "num_steps = 5000\n",
        "\n",
        "# Number of evaluation steps.\n",
        "num_eval_steps = 100\n",
        "  \n",
        "\n",
        "# A batch size determines how many inputs the model will consider at once\n",
        "# for training. Generally a higher batch size increases convergence of the model,\n",
        "# but requires higher graphic memory.\n",
        "# The batch sizes in the given list are for Google Colab (Tesla K80)\n",
        "# You may increase or decrease them if you're running them locally.\n",
        "\n",
        "# We are still testing batch sizes for other models.\n",
        "# This list will be updated for other available models after testing them!\n",
        "\n",
        "MODELS_CONFIG = {\n",
        "    'efficientdet_d0': {\n",
        "        'model_name': 'efficientdet_d0_coco17_tpu-32',\n",
        "        'pipeline_file': 'ssd_efficientdet_d0_512x512_coco17_tpu-8.config',\n",
        "        'batch_size': 8\n",
        "    },\n",
        "}\n",
        "\n",
        "# Pick the model you want to use\n",
        "# Select a model in `MODELS_CONFIG`.\n",
        "selected_model = 'efficientdet_d0'\n",
        "\n",
        "# Load variables related to selection model\n",
        "MODEL = MODELS_CONFIG[selected_model]['model_name']\n",
        "pipeline_file = MODELS_CONFIG[selected_model]['pipeline_file']\n",
        "batch_size = MODELS_CONFIG[selected_model]['batch_size']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3ArDfZ8WLJO"
      },
      "source": [
        "# Initialize directory paths required \n",
        "\n",
        "DATASET_PATH = \"/content/Tensorflow-Object-Detection/\"\n",
        "\n",
        "# We save all the COCO downloaded models under fine_tune_models\n",
        "!mkdir {DATASET_PATH}\"fine_tune_models\"\n",
        "\n",
        "DEST_DIR = DATASET_PATH + \"fine_tune_models/\" + MODEL\n",
        "\n",
        "# This is the directory where we will store our trained checkpoints\n",
        "model_dir = DATASET_PATH + MODEL\n",
        "\n",
        "!mkdir {model_dir}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45PzDKlKWoPx",
        "outputId": "7b4c0a84-d8fa-4624-a839-88d024ddb44d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Your directory should look similar to this\n",
        "\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "annotations\t\t       generate_tfrecord.py\t    test_labels.csv\n",
            "annotations.csv\t\t       images\t\t\t    test.record\n",
            "ed_fix.py\t\t       labelmap.pbtxt\t\t    train_labels.csv\n",
            "efficientdet_d0_coco17_tpu-32  Masked_Face_Detection.ipynb  train.record\n",
            "fine_tune_models\t       README.md\t\t    xml_to_csv.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYfC7AZA0h5B"
      },
      "source": [
        "Now that our data is prepared correctly, we can start with training our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5ieoWGyWiep",
        "outputId": "0fb10292-5fad-4984-9cf1-2a0ffea0cfd3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import os\n",
        "\n",
        "%cd /content/models/research\n",
        "\n",
        "import shutil\n",
        "import glob\n",
        "import urllib.request\n",
        "import tarfile\n",
        "\n",
        "MODEL_FILE = MODEL + '.tar.gz'\n",
        "# This is the base link for all the models pre-trained on COCO 2017\n",
        "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/'\n",
        "\n",
        "# Download the weights for the pre-trained model\n",
        "if not (os.path.exists(MODEL_FILE)):\n",
        "    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
        "\n",
        "tar = tarfile.open(MODEL_FILE)\n",
        "tar.extractall()\n",
        "tar.close()\n",
        "\n",
        "# Delete the .zip file and move to fine_tune_models\n",
        "os.remove(MODEL_FILE)\n",
        "!mv {MODEL} {DEST_DIR}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3c5_kd8bY8Aa"
      },
      "source": [
        "# Initializing other paths required for training\n",
        "\n",
        "test_record_fname = DATASET_PATH + 'test.record'\n",
        "train_record_fname = DATASET_PATH + 'train.record'\n",
        "label_map_pbtxt_fname = DATASET_PATH + 'labelmap.pbtxt'\n",
        "fine_tune_checkpoint = os.path.join(DEST_DIR, \"checkpoint/ckpt-0\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lpGj7KKW3iO"
      },
      "source": [
        "# Tensorflow Object Detection API provides a list of sample configurations \n",
        "# that we can use by modifying the required paths and batch size\n",
        "\n",
        "!cp \"/content/models/research/object_detection/configs/tf2/\"{pipeline_file} {model_dir}\"/\"{pipeline_file}\n",
        "import os\n",
        "\n",
        "pipeline_fname = os.path.join(model_dir, pipeline_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7UK3A4O8dyD"
      },
      "source": [
        "## 2. Building pipeline.config file based on Model Configurations\n",
        "\n",
        "A pipeline.config file is used by a tensorflow model to find the required directories and configurations for the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnYP1uhf3aVh"
      },
      "source": [
        "def get_num_classes(pbtxt_fname):\n",
        "    from object_detection.utils import label_map_util\n",
        "    label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
        "    categories = label_map_util.convert_label_map_to_categories(\n",
        "        label_map, max_num_classes=90, use_display_name=True)\n",
        "    category_index = label_map_util.create_category_index(categories)\n",
        "    return len(category_index.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSLgzl7bZJ-5"
      },
      "source": [
        "# Change the configuration based on our model and data\n",
        "\n",
        "import re\n",
        "\n",
        "num_classes = get_num_classes(label_map_pbtxt_fname)\n",
        "with open(pipeline_fname) as f:\n",
        "    s = f.read()\n",
        "with open(pipeline_fname, 'w') as f:\n",
        "    \n",
        "    # fine_tune_checkpoint\n",
        "    s = re.sub('fine_tune_checkpoint: \".*?\"',\n",
        "               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n",
        "    \n",
        "    # tfrecord files train and test.\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(train2017)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(val2017)(.*?\")', 'input_path: \"{}\"'.format(test_record_fname), s)\n",
        "\n",
        "    # label_map_path\n",
        "    s = re.sub(\n",
        "        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n",
        "\n",
        "    # Set training batch_size.\n",
        "    s = re.sub('batch_size: [0-9]+',\n",
        "               'batch_size: {}'.format(batch_size), s)\n",
        "\n",
        "    # Set training steps, num_steps\n",
        "    s = re.sub('num_steps: [0-9]+',\n",
        "               'num_steps: {}'.format(num_steps), s)\n",
        "    \n",
        "    # Set number of classes num_classes.\n",
        "    s = re.sub('num_classes: [0-9]+',\n",
        "               'num_classes: {}'.format(num_classes), s)\n",
        "    \n",
        "    # Fine-tune checkpoint type\n",
        "    s = re.sub('fine_tune_checkpoint_type: \"classification\"', \n",
        "               'fine_tune_checkpoint_type: \"{}\"'.format('detection'), s)\n",
        "    \n",
        "    s = re.sub('num_epochs: [0-9]+',\n",
        "               'num_epochs: {}'.format(num_eval_steps), s)\n",
        "\n",
        "    f.write(s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXRwgoDCZMai"
      },
      "source": [
        "# Confirm the changes made to the config\n",
        "!cat {pipeline_fname}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swlsLZ2y8ubE"
      },
      "source": [
        "## 3. Training \n",
        "\n",
        "Once we have all the files ready, we can train the model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fbojj3sNZTEz"
      },
      "source": [
        "# Finally, we can start training our model\n",
        "\n",
        "!python /content/models/research/object_detection/model_main_tf2.py \\\n",
        "    --pipeline_config_path={pipeline_fname} \\\n",
        "    --model_dir={model_dir} \\\n",
        "    --alsologtostderr \\\n",
        "    --num_train_steps={num_steps} \\\n",
        "    --sample_1_of_n_eval_examples=1 \\\n",
        "    --num_eval_steps={num_eval_steps}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjhP5I7iZajq",
        "outputId": "b791a49b-ec34-4891-b0ce-4dba49bea63f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Check the files after training.\n",
        "# A model creates checkpoints after some interval of time.\n",
        "\n",
        "# Incase you stop training or run into any error, you can continue training \n",
        "# from the last available checkpoint. This can be used to divide long training\n",
        "# sessions into smaller batches\n",
        "\n",
        "!ls {model_dir}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint\t\t    ckpt-4.index\n",
            "ckpt-1.data-00000-of-00001  ckpt-5.data-00000-of-00001\n",
            "ckpt-1.index\t\t    ckpt-5.index\n",
            "ckpt-2.data-00000-of-00001  ckpt-6.data-00000-of-00001\n",
            "ckpt-2.index\t\t    ckpt-6.index\n",
            "ckpt-3.data-00000-of-00001  ssd_efficientdet_d0_512x512_coco17_tpu-8.config\n",
            "ckpt-3.index\t\t    train\n",
            "ckpt-4.data-00000-of-00001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDPV6ghW86dU"
      },
      "source": [
        "## 4. Exporting the model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6J6MeRnZ0lb"
      },
      "source": [
        "# Now that we trained our model, we can export the model's final checkpoint\n",
        "# This will create a folder named \"export\" in the training directory which \n",
        "# contains the final checkpoint of the trained model\n",
        "\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "output_dir = model_dir + \"/export\"\n",
        "!mkdir {output_dir}\n",
        "\n",
        "!python /content/models/research/object_detection/exporter_main_v2.py \\\n",
        "    --trained_checkpoint_dir={model_dir} \\\n",
        "    --output_directory={output_dir} \\\n",
        "    --pipeline_config_path={pipeline_fname}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-9qquEaZ4Ry",
        "outputId": "2f48ba48-39eb-46ec-d996-3e789ca1d2ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Check the exported files\n",
        "!ls {model_dir}\"/export\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint  pipeline.config  saved_model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9-9LR5f9AWk"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ovMClul9C86"
      },
      "source": [
        "## 1. Test on same dataset\n",
        "\n",
        "Using the exported checkpoint of the model to run Object Detection on our data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Xi4UPyqZ6nz"
      },
      "source": [
        "# Utility library and functions for testing the model\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import glob\n",
        "\n",
        "import io\n",
        "import scipy.misc\n",
        "import numpy as np\n",
        "from six import BytesIO\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "from object_detection.builders import model_builder\n",
        "\n",
        "\n",
        "def load_image_into_numpy_array(path):\n",
        "    \"\"\"Load an image from file into a numpy array.\n",
        "\n",
        "    Puts image into numpy array to feed into tensorflow graph.\n",
        "    Note that by convention we put it into a numpy array with shape\n",
        "    (height, width, channels), where channels=3 for RGB.\n",
        "\n",
        "    Args:\n",
        "        path: the file path to the image\n",
        "\n",
        "    Returns:\n",
        "        uint8 numpy array with shape (img_height, img_width, 3)\n",
        "    \"\"\"\n",
        "    img_data = tf.io.gfile.GFile(path, 'rb').read()\n",
        "    image = Image.open(BytesIO(img_data))\n",
        "    image = image.convert('RGB')\n",
        "    (im_width, im_height) = image.size\n",
        "    return np.array(image.getdata()).reshape(\n",
        "            (im_height, im_width, 3)).astype(np.uint8)\n",
        "\n",
        "\n",
        "def get_model_detection_function(model):\n",
        "    \"\"\"Get a tf.function for detection.\"\"\"\n",
        "\n",
        "    @tf.function\n",
        "    def detect_fn(image):\n",
        "        \"\"\"Detect objects in image.\"\"\"\n",
        "\n",
        "        image, shapes = model.preprocess(image)\n",
        "        prediction_dict = model.predict(image, shapes)\n",
        "        detections = model.postprocess(prediction_dict, shapes)\n",
        "\n",
        "        return detections, prediction_dict, tf.reshape(shapes, [-1])\n",
        "\n",
        "    return detect_fn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XABQMM8cZ7sr",
        "outputId": "f6e33193-c3f3-44fa-c520-dc2d6b8014ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Load the configurations, initialize paths and resotore the export checkpoint\n",
        "\n",
        "MODEL_TEST = model_dir + \"/export/\"\n",
        "\n",
        "pipeline_config = MODEL_TEST + 'pipeline.config'\n",
        "model_dir_test = MODEL_TEST + 'checkpoint/ckpt-0'\n",
        "configs = config_util.get_configs_from_pipeline_file(pipeline_config)\n",
        "model_config = configs['model']\n",
        "detection_model = model_builder.build(\n",
        "            model_config=model_config, is_training=False)\n",
        "\n",
        "ckpt = tf.compat.v2.train.Checkpoint(\n",
        "            model=detection_model)\n",
        "ckpt.restore(os.path.join(model_dir_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f8518271828>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CsYViF6Z-Xi"
      },
      "source": [
        "# load labelmap, map them to it's labels and load the detector\n",
        "\n",
        "detect_fn = get_model_detection_function(detection_model)\n",
        "\n",
        "#map labels for inference decoding\n",
        "label_map_path = label_map_pbtxt_fname\n",
        "label_map = label_map_util.load_labelmap(label_map_path)\n",
        "categories = label_map_util.convert_label_map_to_categories(\n",
        "        label_map,\n",
        "        max_num_classes=label_map_util.get_max_label_map_index(label_map),\n",
        "        use_display_name=True)\n",
        "category_index = label_map_util.create_category_index(categories)\n",
        "label_map_dict = label_map_util.get_label_map_dict(label_map, use_display_name=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdVXGyOEaAj_"
      },
      "source": [
        "# Run the detector on image samples\n",
        "\n",
        "import random\n",
        "import cv2\n",
        "import glob\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Images from this path will be considered for testing\n",
        "# Change the extension accordingly if your dataset is not png\n",
        "TEST_IMAGE_PATHS = glob.glob(DATASET_PATH + 'images/*.png')\n",
        "\n",
        "# Change the value of k to the number of images to be considered for testing\n",
        "try:\n",
        "    images = random.sample(TEST_IMAGE_PATHS, k=5)\n",
        "except:\n",
        "  # Exception incase the value of k is higher than available samples\n",
        "    images = TEST_IMAGE_PATHS\n",
        "\n",
        "\n",
        "for image_path in images:\n",
        "    print(image_path)\n",
        "    image_np = load_image_into_numpy_array(image_path)\n",
        "        \n",
        "    input_tensor = tf.convert_to_tensor(\n",
        "            np.expand_dims(image_np, 0), dtype=tf.float32)\n",
        "    detections, predictions_dict, shapes = detect_fn(input_tensor)\n",
        "\n",
        "    label_id_offset = 1\n",
        "    image_np_with_detections = image_np.copy()\n",
        "\n",
        "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "                image_np_with_detections,\n",
        "                detections['detection_boxes'][0].numpy(),\n",
        "                (detections['detection_classes'][0].numpy() + label_id_offset).astype(int),\n",
        "                detections['detection_scores'][0].numpy(),\n",
        "                category_index,\n",
        "                use_normalized_coordinates=True,\n",
        "                max_boxes_to_draw=200,\n",
        "                min_score_thresh=.6,\n",
        "                agnostic_mode=False,\n",
        "    )\n",
        "\n",
        "    cv2_imshow(cv2.cvtColor(image_np_with_detections, cv2.COLOR_BGR2RGB))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "biq977cZ9loN"
      },
      "source": [
        "## 2. Test on custom uploaded data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtlrqSNQCQgY"
      },
      "source": [
        "# If you would like to test the model on your data, \n",
        "# create a folder named custom data and manually upload your files here\n",
        "\n",
        "!mkdir {DATASET_PATH}custom_data\n",
        "%cd {DATASET_PATH}custom_data\n",
        "\n",
        "# Upload the images from your local files; you can upload multiple images at once\n",
        "\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9c-0fP3nL6V_"
      },
      "source": [
        "# Same test cell from above, only image extension is changed\n",
        "\n",
        "\n",
        "import random\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "TEST_IMAGE_PATHS = glob.glob(DATASET_PATH + \"custom_data/*.*\")\n",
        "\n",
        "images = TEST_IMAGE_PATHS\n",
        "for image_path in images:\n",
        "    print(image_path)\n",
        "    try:\n",
        "        image_np = load_image_into_numpy_array(image_path)\n",
        "    except:\n",
        "        print(\"Invalid Image format:\", image_path)\n",
        "        continue\n",
        "        \n",
        "    input_tensor = tf.convert_to_tensor(\n",
        "            np.expand_dims(image_np, 0), dtype=tf.float32)\n",
        "    detections, predictions_dict, shapes = detect_fn(input_tensor)\n",
        "\n",
        "    label_id_offset = 1\n",
        "    image_np_with_detections = image_np.copy()\n",
        "\n",
        "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "                image_np_with_detections,\n",
        "                detections['detection_boxes'][0].numpy(),\n",
        "                (detections['detection_classes'][0].numpy() + label_id_offset).astype(int),\n",
        "                detections['detection_scores'][0].numpy(),\n",
        "                category_index,\n",
        "                use_normalized_coordinates=True,\n",
        "                max_boxes_to_draw=200,\n",
        "                min_score_thresh=.6,\n",
        "                agnostic_mode=False,\n",
        "    )\n",
        "\n",
        "    cv2_imshow(cv2.cvtColor(image_np_with_detections, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "\n",
        "# Removed output to hide my model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlwWRBCd9Uuy"
      },
      "source": [
        "# Download the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gx3wEX4oQo78"
      },
      "source": [
        "# Download your trained model for future use or integration in other projects\n",
        "\n",
        "!zip -r /content/model.zip {MODEL_TEST}\n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"/content/model.zip\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwokuaJl9rmW"
      },
      "source": [
        "Thank you for following us till the end. If you run into any issues, you can write a comment.\n",
        "\n",
        "We love to hear feedback and your reviews encourage us to provide more quality content in the coming future. Check out the blog for an explanation of the process or to drop reviews, feedbacks or issues."
      ]
    }
  ]
}